{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib. pyplot as plt \n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate box plot parameters\n",
    "def get_box_plot_data(labels, bp):\n",
    "    rows_list = []\n",
    "    for i in range(len(labels)):\n",
    "        dict1 = {}\n",
    "        dict1['label'] = labels[i]\n",
    "        dict1['lower_whisker'] = bp['whiskers'][i * 2].get_ydata()[1]\n",
    "        dict1['lower_quartile'] = bp['boxes'][i].get_ydata()[1]\n",
    "        dict1['median'] = bp['medians'][i].get_ydata()[1]\n",
    "        dict1['upper_quartile'] = bp['boxes'][i].get_ydata()[2]\n",
    "        dict1['upper_whisker'] = bp['whiskers'][(i * 2) + 1].get_ydata()[1]\n",
    "        rows_list.append(dict1)\n",
    "    return pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove noise and normalize reuse score\n",
    "def reuseScore(dataset_name):\n",
    "    matrix = os.path.join(ROOT_PATH+'/data',dataset_name)\n",
    "    data = pd.read_csv(matrix)\n",
    "    \n",
    "    ## drop first column and calculate threshold\n",
    "    df=data.copy()\n",
    "    df=df.drop(df.columns[0], axis=1)\n",
    "    arr = df.values.flatten()\n",
    "    median = np.mean(arr)\n",
    "    threshold= median * 0.1\n",
    "    \n",
    "    data_frame = data.copy()\n",
    "    data_frame.drop(data_frame.columns[0], axis=1, inplace=True)\n",
    "    data_frame[data_frame < 0] = 0\n",
    "    \n",
    "    ## normalize reuse score\n",
    "    for i, row in data_frame.iterrows():\n",
    "        count = 0\n",
    "        summary=0\n",
    "        for col in data_frame.columns:\n",
    "           cell = data_frame.loc[df.index[i], col]\n",
    "           if cell>threshold:\n",
    "               count=count+1\n",
    "               summary=summary+cell\n",
    "        if count>0:\n",
    "             data_frame.at[i, 'score'] = summary/count\n",
    "        else:\n",
    "            data_frame.at[i, 'score'] =0\n",
    "            \n",
    "    repos_id = data_frame.columns\n",
    "    lst = repos_id[:len(repos_id)-1]\n",
    "\n",
    "    reuse_score = pd.DataFrame({\n",
    "            \"repo_id\": lst,\n",
    "            \"reuse_score\": data_frame['score']\n",
    "        })\n",
    "    return reuse_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate quality score for each dataset\n",
    "def scoring_quality(dataset_name):\n",
    "    matrix = os.path.join(ROOT_PATH+'\\\\repository',dataset_name)\n",
    "    score = pd.read_csv(matrix)\n",
    "    matrix = os.path.join(ROOT_PATH+'\\\\commits',dataset_name)\n",
    "    commits = pd.read_csv(matrix, header=0)\n",
    "    arr = commits['committer'].groupby(commits['repo_id']).agg(['nunique'])\n",
    "    arr.columns = ['contributors']\n",
    "    score = score.merge(arr, on='repo_id')\n",
    "\n",
    "    labels = ['stargazers', 'subscribers', 'forks', 'contributors']\n",
    "    bp = plt.boxplot([score['stargazers_count'], score['subscribers_count'],\n",
    "                      score['forks_count'], score['contributors']], labels=labels, showfliers=False)\n",
    "    plt.close()\n",
    "\n",
    "    dictionary = get_box_plot_data(labels, bp)\n",
    "    upper_stars = dictionary['upper_whisker'][0]\n",
    "    upper_subs = dictionary['upper_whisker'][1]\n",
    "    upper_forks = dictionary['upper_whisker'][2]\n",
    "    upper_contributors = dictionary['upper_whisker'][3]\n",
    "\n",
    "    for i, row in score.iterrows():\n",
    "        s = {}\n",
    "        has_wiki=0.1\n",
    "        if upper_stars != 0:\n",
    "            s['s1'] = 1 if row['stargazers_count'] > upper_stars else row['stargazers_count'] / upper_stars\n",
    "        if upper_subs != 0:\n",
    "            s['s2'] = 1 if row['subscribers_count'] > upper_subs else row['subscribers_count'] / upper_subs\n",
    "        if upper_forks != 0:\n",
    "            s['s3'] = 1 if row['forks_count'] > upper_forks else row['forks_count'] / upper_forks\n",
    "        if upper_contributors != 0:\n",
    "            s['s5'] = 1 if row['contributors'] > upper_contributors else row['contributors'] / upper_contributors\n",
    "        if row['has_wiki'] == 0:\n",
    "            has_wiki = 0\n",
    "            \n",
    "        \n",
    "        score.at[i, 'quality_score'] = ( (sum(s.values()) / 0.9) + has_wiki)\n",
    "\n",
    "    result = score['quality_score'].groupby(score['repo_id']).unique().apply(pd.Series)\n",
    "    result.columns = ['quality_score']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataset_name, quality_score, reuse_score):\n",
    "    merge = reuse_score.merge(quality_score,on='repo_id')\n",
    "    merge = merge.drop([\"repo_id\"], axis=1)\n",
    "    corr= merge.corr()\n",
    "    print(\"Correlation for Database \"+ dataset_name+\" :\" )\n",
    "    print(corr)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mzmir\\PycharmProjects\\AdvancedSE\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles = [f for f in listdir(ROOT_PATH+'//data') if isfile(join(ROOT_PATH+'//data', f)) and  f.endswith(\".csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation for Database db.csv :\n",
      "               reuse_score  quality_score\n",
      "reuse_score       1.000000      -0.036586\n",
      "quality_score    -0.036586       1.000000\n",
      "\n",
      "Correlation for Database os.csv :\n",
      "               reuse_score  quality_score\n",
      "reuse_score       1.000000      -0.165695\n",
      "quality_score    -0.165695       1.000000\n",
      "\n",
      "Correlation for Database tetris.csv :\n",
      "               reuse_score  quality_score\n",
      "reuse_score       1.000000      -0.039818\n",
      "quality_score    -0.039818       1.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for f in onlyfiles:\n",
    "    q = scoring_quality(f)\n",
    "    r = reuseScore(f)\n",
    "    correlation(f,q,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
